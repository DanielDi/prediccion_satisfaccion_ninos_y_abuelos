---
title: ''
author: ''
date: ''
output:
  html_document:
    df_print: paged
  pdf_document: default
lang: es
---
\begin{titlepage}
\centering
{\scshape\Huge Informe Técnico \par}
{\scshape\Huge  Satisfacción de Niños y Abuelos \par}
\vspace{2cm}
{\Large Por: \par}
{\Large Daniel Espinal Mosquera\par}
{\Large Juan Sebastián Falcón\par}
{\Large Juan F. Peña Tamayo\par}
{\Large Brayan M. Ortiz Fajardo\par}
{\Large Thalea Marina Hesse\par}
\vfill
\vspace{0.5cm}

```{r echo=FALSE, out.width = "300px", out.height="150px",fig.align='center'}
knitr::include_graphics("Imagenes/LOGO.png")

```
\vfill
\vspace{0.5cm}
{\bfseries\LARGE Universidad Nacional de Colombia \par Sede Medellín \par}
\vspace{1cm}
\end{titlepage}

```{r setup, include=FALSE, echo=FALSE}
library(caret)
library(party)
library(ggplot2)
library(dplyr)
library(hrbrthemes)
library(readxl)
library(dplyr)
require(ggplot2)
require(corrplot)
library(reshape2)
require(kableExtra)
require(ggcorrplot)
require(magrittr)
library(naniar)
library(Metrics)
library(polycor)

knitr::opts_chunk$set(echo = TRUE)
```

# Introducción 

La satisfacción de la vida y la felicidad varía entre países [7] y juegan un papel importante en el desarrollo de un país. Sin embargo, no se logró determinar documentación o estudios relacionados sobre cómo se pueden predecir estos factores en Colombia dados unos parámetros. Por tal motivo, se propone el plantemiento, desarrollo, análisis y posterior productización de un modelo con el cual se busca predecir la satisfacción de niños y abuelos. Para lograr esto, se toma como base una encuesta realizada por el DANE en el 2020: Colombia - Encuesta Nacional de Calidad de Vida - ECV 2020. Esta investigación, según el DANE "Busca cuantificar y caracterizar las condiciones socioeconómicas de los hogares colombianos, con el fin de obtener la información necesaria para la actualización de indicadores sociales a nivel de viviendas, hogares y personas, y para la definición de políticas que permitan diseñar y ejecutar planes sociales." (Metodologia ECV, 2009, p.17)   
La estructura del estudio se planteó de la siguiente manera: se hizo una búsqueda exhaustiva sobre documentación para determinar cuáles de las variables que se tienen afectan de manera significativa la satisfacción. Después se planteó un modelo general, sin embargo al revisar las correlaciones entre las variables predictoras se dicidió partir ese modelo general en tres sub-modelos: satisfacción de salud, seguridad y trabajo. Para cada cada uno de estos también se realizó la búsqueda de documentación al respecto. Adicionalmente, se creó una página web para poder interactuar con los modelos. Finalmente, se obtuvieron los resultados y plantearon las conclusiones. 

# Planteamiento del Problema 

El Instituto Colombiano de Bienestar Familiar es una entidad que trabaja por la prevención y protección integral de la primera infancia, la niñez, la adolescencia y el bienestar general de las familias en Colombia, llegando a millones de colombianos mediante sus programas, estrategias y servicios de atención.  En el marco de los objetivos de esta institución se encontró que el ICBF actualmente no cuenta con una herramienta para conocer en prospectiva, y de forma adecuada y efectiva la satisfacción general de vida tanto de niños como de adultos en la tercera edad. Es para ellos de vital importancia conocer esta información pues es un indicador fundamental a tener en cuenta a la hora de crear programas preventivos y de protección que tienen como objetivo el mejoramiento de vida de la población destinataria. Por esto se busca implementar en el ICBF tanto los 2 sub-modelos como el modelo de satisfacción general, para que sea usado por la institución en pro de mejorar futuros planeamientos en todo proyecto social que involucre niños y adultos de la tercera edad como población objetivo.    


# Justificación 
## Niños

En primera instancia se planteó tomar a los niños en dos grupos, uno perteneciente a la primera infancia (0 a 5 años) y otro con aquellos niños con edad entre 6 y 12 años. Sin embargo, luego se decidió que se tomaría como niño la definición integrada en el codigo de infancia y adolesencia, donde se expone que "Para todos los efectos de esta ley son sujetos titulares de derechos todas las personas menores de 18 años. Sin perjuicio de lo establecido en el artículo 34 del Código Civil, se entiende por niño o niña las personas entre los 0 y los 12 años, y por adolescente las personas entre 12 y 18 años de edad"(Articulo 3).

Una vez adoptada esta definición se analizó cuantas observaciones de la ECV cumplían esta condición, resultando en un total de 56128 niños.


## Abuelos

Para los abuelos, al igual que con los niños, se pensó inicialmente en tomar un rango de edad que abarcara la definición popular de este colectivo, los adultos de la tercera edad (mayores de 60 años). Sin embargo, luego se planteó tener en cuenta cuál es la definición literal de abuelo: personas con nietos;  y mediante un sistema de grafos se logró determinar la cantidad de hombres y mujeres cumplían esta condición. Filtrandolos por su rango edad se observó que se tienen registrados un total de 1467 abuelos mayores de 60 años, y 1049 abuelos menores de 60 años.

Se observa que con la definición inicial se estaba omitiendo un total de 1049 observaciones, ademas, se observa que los abuelos resgitrados en la base de datos son relativamente pocos pues solo representan aproximadamente el 3% del total de personas.

Ante esta situación se toma la desicion trabajar únicamente con las personas de la tercera edad.

```{r lectura_datos, echo=F}
personas <- read.csv2("Datos/personas.csv", header=TRUE, dec=".", encoding="UTF-8")
salud <- read.csv2("Datos/salud.csv", header=TRUE, dec=".", encoding="UTF-8")
educacion <- read.csv2("Datos/educacion.csv", header=TRUE, dec=".", encoding="UTF-8")
cond_hogar <- read.csv2("Datos/condiciones_hogar.csv", header=TRUE, dec=".", encoding="UTF-8")
datos_vivienda <- read.csv2("Datos/datos_vivienda.csv", header=TRUE, dec=".", encoding="UTF-8")
serv_hogar <- read.csv2("Datos/servicios_hogar.csv", header=TRUE, dec=".", encoding="UTF-8")
fuerza_trabajo <- read.csv2("Datos/fuerza_trabajo.csv", header=TRUE, dec=".", encoding="UTF-8")
comp_hogar <- read.csv2("Datos/caracteristicas_composicion_del_hogar.csv", header=TRUE, dec=".", encoding="UTF-8")
```

# Modelos Predictivos
Inicialmente, se intentó englobar en un modelo a los abuelos y niños con el fin de predecir la satisfacción. Sin embargo, como lo ilustra la Figura 1, las variables objetivos que se seleccionaron no fueron respondidas, en su mayoría, por niños. Este comportamiento se asemeja con los resultados encontrados en [7], donde se puede observar que los abuelos y niños tienen diferentes definiciones de satisfacción y, por ende, diferentes factores que la influyen. Por esta razón, se decidió trabajar de forma independiente los modelos para los niños y abuelos. 

## Modelos Predictivos en Abuelos

```{r, echo = FALSE}
# Descarta los datos que no son de 3ra edad.
df_abuelos <- subset(personas, personas$Clasificación == "3ra_edad")
```

## Seleccion de Variables

De [1] y [2] se obtuvieron las variables para el modelo general. Se realizó un mapeo con las que se tenían en la base de datos del DANE y se eligieron las siguientes: 

```{r, echo = F}
vars_gen <- matrix(c("NIVEL_DE_EDUCACION", "SEXO", "SALUD_AUTOPERCIBIDA", "ESTADO_CIVIL",
                "ETNIA", "INGRESO_AUTOPERCIBIDO", "SEGURIDAD_AUTOPERCIBIDA", 
                "TRABAJO_AUTOPERCIBIDO", "SATISFACCION", "I_HOGAR", 
                "PERCAPITA", "COND_VIDA_DEL_HOGAR"), ncol=3, byrow=TRUE)
vars_gen <- as.data.frame(vars_gen)                  # Convert table to data.frame
vars_gen
```

Cada una de estas variables mostraron correlación en los estudios realizados sobre factores que influyen en la satisfacción de la vida en abuelos. En [2] también mencionan variables que involucran relaciones sociales, sin embargo en la base de datos no se logró de terminar alguna asociación lógica para este tipo de variables.

## Estructura

Análogamente a la divergencia entre modelos para niños y abuelos, después de realizar un análisis de correlaciones entre todas las variables:

```{r correlación_satisfacción ,echo=F}
varsGeneral <- personas %>% select(-ID_Persona,-Clasificación,-SEXO) %>% na.omit() 
M = cor(varsGeneral)
ggcorrplot(M, hc.order = TRUE, type = "lower",
   lab = TRUE,tl.cex = 8, pch.col = "red",lab_size = 2)
```

se llegó a la conclusión de partir el modelo en 4: uno para predecir la satisfacción en general; otro para la satisfacción de la salud; para la satisfacción en cuanto a seguridad; y, finalmente, para la satisfacción laboral.

A continuación se presenta cada modelo por separado.

### Satisfacción de la Vida en General

### Análisis Descriptivo

### Matriz de Correlaciones

Después de analizar la matriz de correlación general, se puede observar que las variables con mayor relación a la satisfacción son: SALUD_AUTOPERCIBIDA, SEGURIDAD_AUTOPERCIBIDA, NIVEL_DE_EDUCACION, COND_VIDA_DEL_HOGAR, TRABAJO_AUTOPERCIBIDO.

```{r, echo = F}

# Se reemplaza los valores NaNs por la moda.
moda_cond_hogar <- as.numeric(names(which.max(table(df_abuelos$COND_VIDA_DEL_HOGAR))))
df_abuelos$COND_VIDA_DEL_HOGAR <- replace(df_abuelos$COND_VIDA_DEL_HOGAR, is.na(df_abuelos$COND_VIDA_DEL_HOGAR), moda_cond_hogar)

varsGeneral <- subset(df_abuelos, select = c(SATISFACCION, SALUD_AUTOPERCIBIDA, SEGURIDAD_AUTOPERCIBIDA, 
                                     NIVEL_DE_EDUCACION, COND_VIDA_DEL_HOGAR, TRABAJO_AUTOPERCIBIDO))

M = cor(varsGeneral)
ggcorrplot(M, hc.order = TRUE, type = "lower",
   lab = TRUE,tl.cex = 8, pch.col = "red",lab_size = 2)
```
 
```{r, echo = FALSE}
# Se descartan las columnas que no hacen parte de la predicción
datos <- subset(df_abuelos, select = c(SATISFACCION, SALUD_AUTOPERCIBIDA, SEGURIDAD_AUTOPERCIBIDA, 
                                     NIVEL_DE_EDUCACION, COND_VIDA_DEL_HOGAR, TRABAJO_AUTOPERCIBIDO))

# Por facilidad, se renombran las variables a Xi, 1 <= i <= 11
names(datos) <- c('Y', 'X1','X2', 'X3', 'X4', 'X5')

save(file="App/data/dfdatos.RData",
                              list=c("datos"))

```

de las cuales se toma como variable objetivo la SATISFACCIÓN y como variables predictoras las demás.

### Modelo con Regresion Lineal

Para predecir las satisfacción se utilizó la regresión lineal ya que este modelo fue el que mejor se acomodó a los datos. Para esto, se dividió los datos en entrenamiento (75%) y prueba (25%). Luego se entrena el modelo y finalmente se realizan las predicciones con los datos de prueba.

```{r, echo=FALSE}
set.seed(27042022) # se fija por reproducibilidad


# Separación de los datos en entrenamiento y prueba
datos1 <- sample(2, nrow(datos),
                   replace = T,
                   prob = c(0.75, 0.25))

train <- datos[datos1 == 1,]
test <- datos[datos1 == 2,]

# Train

lm1 <- lm(formula = Y ~ . , data=train )
summary(lm1)

test$Y_Predict <- predict(lm1, newdata=test)
head(test[ , c('Y', 'Y_Predict')])

# Conexión con la aplicación
#SATISFACCION, SALUD_AUTOPERCIBIDA, SEGURIDAD_AUTOPERCIBIDA, 
#                                     NIVEL_DE_EDUCACION, COND_VIDA_DEL_HOGAR, TRABAJO_AUTOPERCIBIDO
save(file="App/data/modeloSatisfaccion.RData",
                              list=c("lm1"))
```
### Análisis del modelo

Se presenta una gráfica de los Predichos vs Observados:

```{r, echo = F}
plot(test$Y_Predict,test$SATISFACCION,
     main = c("Predichos (remendados) vs Observados","Validación"),
     xlim = c(0,10), ylim = c(0,10),
     las=1, xlab = "Valores predichos (remendados)",
     ylab = "Valores observados")
```
Además, las medidades de error son las siguientes:
```{r, echo = F}
MSE_VIDA <- mse(test$SATISFACCION, test$Y_Predict)
MAE_VIDA <- mae(test$SATISFACCION, test$Y_Predict)
```

* *MSE*: `r MSE_VIDA`  
* *MAE*: `r MAE_VIDA`

### Satisfacción en la Salud

Para determinar las variables predictoras de este modelo se tomó como base el estudio [4]. En este estudio, explican los factores que afectan en la satisfacción y calidad de la salud. Estas son las variables que se seleccionaron:

```{r, echo = F}
vars_gen <- matrix(c("AFILIADO", "PAGO_EPS", "CALIDAD_PRESTADOR", "ESTADO_SALUD",
                "TIPO_PAGO", "REGIMEN", "ENFERMEDAD_CRONICA", "", ""), ncol=3, byrow=TRUE)
vars_gen <- as.data.frame(vars_gen)
names(vars_gen) <- NULL
vars_gen
```

### Análisis Descriptivo

```{r, echo = FALSE}
# Une las tablas
df_salud <- merge(x = comp_hogar, y = salud, by = "ID_Persona")
df_salud <- merge(x = datos_vivienda, y = df_salud, by = "DIRECTORIO")

# Selecciona solo las personas de 3era edad
df_salud <- subset(df_salud, df_salud$Clasificación == "3ra_edad")

# Selecciona las variables de interés
df_salud <- subset(df_salud, select = c("P1897", "P6181", "P6127", "P8520S1A1", "P6100", "P1930"))

# Cambia los nombres de las columnas
names(df_salud) = c("SATISFACCION", "CALIDAD_EPS", "ESTADO_SALUD", "ESTRATO", "REGIMEN", "ENFERMEDAD_CRONICA")

save(file="App/data/dfSalud.RData",
                              list=c("df_salud"))

```

### Matriz de Correlaciones
```{r, echo = FALSE}
M <- cor(df_salud)
ggcorrplot(M, hc.order = TRUE, type = "lower",
   lab = TRUE,tl.cex = 8, pch.col = "red",lab_size = 2)
```

### Modelo con Regresion Lineal

Análogamente, para predecir las satisfacción de seguridad se utilizó la regresión lineal ya que este modelo fue el que mejor se acomodó a los datos. Para esto, se devide los datos en entrenamiento (75%) y prueba (25%). Luego se entrena el modelo y finalmente se realizan las predicciones con los datos de prueba.

```{r, echo=FALSE}
set.seed(27042022) # se fija por reproducibilidad


# Separación de los datos en entrenamiento y prueba
datos_salud <- sample(2, nrow(df_salud),
                   replace = T,
                   prob = c(0.75, 0.25))

train_salud <- df_salud[datos_salud == 1,]
test_salud <- df_salud[datos_salud == 2,]

# Train
head(train_salud)
lm_salud <- lm(formula = SATISFACCION ~ . , data=train_salud)
summary(lm_salud)

test_salud$Y_Predict <- predict(lm_salud, newdata=test_salud)
head(test_salud[ , c('SATISFACCION', 'Y_Predict')])

save(file="App/data/modeloSatisfaccionSalud.RData",
                              list=c("lm_salud"))

str(train_salud)
```

### Análisis del modelo

Se presenta una gráfica de los Predichos vs Observados:

```{r, echo = F}
plot(test_salud$Y_Predict,test_salud$SATISFACCION,
     main = c("Predichos (remendados) vs Observados","Validación"),
     xlim = c(0,10), ylim = c(0,10),
     las=1, xlab = "Valores predichos (remendados)",
     ylab = "Valores observados")
```

Además, las medidades de error son las siguientes:
```{r, echo = F}
MSE_SALUD <- mse(test_salud$SATISFACCION, test_salud$Y_Predict)
MAE_SALUD <- mae(test_salud$SATISFACCION, test_salud$Y_Predict)
```

* *MSE*: `r MSE_SALUD`  
* *MAE*: `r MAE_SALUD`

### Satisfacción sobre el Nivel de Seguridad

En este caso se la selección de variables se basó en [6]. Allí exploran los factores de seguridad en un barrio, además muestran problemas psicológicos que pueden influenciar en cómo percibe una persona la seguridad en un ambiente. Con base a los factores descritos allí y comparando las variables que se tienen en la base de datos, se escogieron las siguientes variables:

```{r, echo = F}
vars_gen <- matrix(c("ESTADO_CIVIL", "SEXO", "ESTRATO", "NIVEL_DE_SEGURIDAD",
                "CONDICIONES_DE_VIDA_HOGAR", "ES_CAMPESINO", "CAI", "ROBO", 
                "OTRO_DELITO", "LEE_ESCRIBE"), ncol=2, byrow=TRUE)
vars_gen <- as.data.frame(vars_gen)
names(vars_gen) <- NULL
vars_gen
```

#### Análisis Descriptivo
```{r, echo = FALSE}
# Une las tablas

df_seguridad <- merge(x = comp_hogar, y = fuerza_trabajo, by = "ID_Persona")
df_seguridad <- merge(x = df_seguridad, y = educacion, by = "ID_Persona")
df_seguridad <- merge(x = df_seguridad, y = cond_hogar, by = "ID_Hogar")
df_seguridad <- merge(x = df_seguridad, y = datos_vivienda, by = "DIRECTORIO")

# Selecciona solo las personas de 3era edad
df_seguridad <- subset(df_seguridad, df_seguridad$Clasificación == "3ra_edad")

# Selecciona las variables de interés
df_seguridad <- subset(df_seguridad, select = c("P1898", "P5502", "P6020", "P8520S1A1",
                                                "P9010", "P9030", "P2059",
                                                "P1913S5", "P9025S2", "P9025S1", "P6160"))

# Cambia los nombres de las columnas
names(df_seguridad) = c("SATISFACCION", "ESTADO_CIVIL", "SEXO", "ESTRATO",
                        "NIVEL_DE_SEGURIDAD", "CONDICIONES_DE_VIDA_HOGAR",
                      "ES_CAMPESINO","CAI", "OTRO_DELITO", "ROBO", "LEE_ESCRIBE")


save(file="App/data/dfSeguridad.RData",
                              list=c("df_seguridad"))
```

### Matriz de Correlaciones Pearson

```{r, echo = FALSE}
M <- cor(df_seguridad)
ggcorrplot(M, hc.order = TRUE, type = "lower",
    lab = TRUE,tl.cex = 8, pch.col = "red",lab_size = 2)
```

### Correlaciones Polychoric

Para tener mayor certeza sobre la relación entre variables, se hace uso del método Polychoric y se obtuvieron los siguientes resultados:
```{r, echo = FALSE}

corr1 <- polychor(df_seguridad$SATISFACCION, df_seguridad$ESTADO_CIVIL)
corr2 <- polychor(df_seguridad$SATISFACCION, df_seguridad$SEXO)
corr3 <- polychor(df_seguridad$SATISFACCION, df_seguridad$ESTRATO)
corr4 <- polychor(df_seguridad$SATISFACCION, df_seguridad$NIVEL_DE_SEGURIDAD)
corr5 <- polychor(df_seguridad$SATISFACCION, df_seguridad$CONDICIONES_DE_VIDA_HOGAR)
corr6 <- polychor(df_seguridad$SATISFACCION, df_seguridad$ES_CAMPESINO)
corr7 <- polychor(df_seguridad$SATISFACCION, df_seguridad$CAI)
corr8 <- polychor(df_seguridad$SATISFACCION, df_seguridad$ROBO)
corr9 <- polychor(df_seguridad$SATISFACCION, df_seguridad$OTRO_DELITO)
corr10 <- polychor(df_seguridad$SATISFACCION, df_seguridad$LEE_ESCRIBE)

cor_poly <- data.frame(ESTADO_CIVIL = c(corr1), SEXO = c(corr2), 
                       ESTRATO = c(corr3), NIVEL_DE_SEGURIDAD  = c(corr4), 
                       CONDICIONES_DE_VIDA_HOGAR  = c(corr5), ES_CAMPESINO = c(corr6),
                       CAI = c(corr7), ROBO = c(corr8), OTRO_DELITO = c(corr9),
                       LEE_ESCRIBE = c(corr10))
cor_poly
```

Por tal motivo, se decide eliminar las variables SEXO, ESTRATO, ES_CAMPESINO y CAI ya que no presentan un correlación significativa con la variable objetivo.

```{r, echo = FALSE}
df_seguridad = subset(df_seguridad, select = c(-SEXO, -ESTRATO, -ES_CAMPESINO, -CAI))
```

### Modelo con Regresion Lineal

Aquí también la regresión lineal fue el modelo elegido para predecir la satisfacción. Para esto, se devide los datos en entrenamiento (75%) y prueba (25%). Luego se entrena el modelo y finalmente se realizan las predicciones con los datos de prueba.

```{r, echo=FALSE}
set.seed(27042022) # se fija por reproducibilidad


# Separación de los datos en entrenamiento y prueba
datos_seguridad <- sample(2, nrow(df_seguridad),
                   replace = T,
                   prob = c(0.75, 0.25))

train_seguridad <- df_seguridad[datos_seguridad == 1,]
test_seguridad <- df_seguridad[datos_seguridad == 2,]

# Train
lm_seguridad <- lm(formula = SATISFACCION ~ . , data=train_seguridad)
summary(lm_seguridad)

test_seguridad$Y_Predict <- predict(lm_seguridad, newdata=test_seguridad)
head(test_seguridad[ , c('SATISFACCION', 'Y_Predict')])

save(file="App/data/modeloSatisfaccionSeguridad.RData",
                              list=c("lm_seguridad"))
```

### Análisis del modelo

Se presenta una gráfica de los Predichos vs Observados:

```{r}
plot(test_seguridad$Y_Predict,test_seguridad$SATISFACCION,
     main = c("Predichos (remendados) vs Observados","Validación"),
     xlim = c(0,10), ylim = c(0,10),
     las=1, xlab = "Valores predichos (remendados)",
     ylab = "Valores observados")
```

Además, las medidades de error son las siguientes:
```{r, echo = F}
MSE_SEGURIDAD <- mse(test_seguridad$SATISFACCION, test_seguridad$Y_Predict)
MAE_SEGURIDAD <- mae(test_seguridad$SATISFACCION, test_seguridad$Y_Predict)
```
* *MSE*: `r MSE_SEGURIDAD`  
* *MAE*: `r MAE_SEGURIDAD`


### Satisfacción en el Trabajo
Finalmente, las características predictoras de la satisfacción del trabajo fueron obtenidas siguiendo [5]. Este estudio presenta unas variables relacionadas con la satisfacción laboral y correlaciones entre sí. Basados en estas variables, se buscaron los análogos en la base de datos que se tiene y se lograron de terminar las siguientes:

```{r, echo = F}
vars_gen <- matrix(c("SEXO", "CARGO", "TIENE_CONTRATO", "SALARIO",
                "HORAS_LABORALES", "RECIBIO_PRIMAS", "RECIBIO_PENSIONES", ""), ncol=2, byrow=TRUE)
vars_gen <- as.data.frame(vars_gen)
names(vars_gen) <- NULL
vars_gen
```

#### Análisis Descriptivo

```{r, echo = FALSE}
# Une las tablas
df_trabajo <- merge(x = comp_hogar, y = fuerza_trabajo, by = "ID_Persona")
df_trabajo <- merge(x = df_trabajo, y = salud, by = "ID_Persona")
df_trabajo <- merge(x = df_trabajo, y = cond_hogar, by = "ID_Hogar")

# Selecciona solo las personas de 3era edad
df_trabajo <- subset(df_trabajo, df_trabajo$Clasificación == "3ra_edad")

# Selecciona las variables de interés
df_trabajo <- subset(df_trabajo, select = c("P1899", "P6020", "P6435", "P6440", 
                                        "P6460", "P8624", "P415", "P8631", "P8642"))
# Cambia los nombres de las columnas
names(df_trabajo) = c("SATISFACCION", "SEXO", "CARGO", "TIENE_CONTRATO", "TIPO_CONTRATO",
                      "SALARIO", "HORAS_LABORALES", "RECIBIO_PRIMAS", "RECIBIO_PENSIONES")
```

#### Datos Faltantes

Para este dataframe se tiene la siguiente cantidad de abuelos:
```{r, echo=FALSE}
count(df_trabajo, name = "Cantidad de Abuelos")
```
Sin embargo, si se observa la cantidad de abuelos que respondieron a las preguntas seleccionadas:
```{r, echo=FALSE}
gg_miss_upset(subset(df_trabajo, select = c(-RECIBIO_PRIMAS, -RECIBIO_PENSIONES)))
```

se puede determinar que la mayoría de estos no respondieron a las preguntas que se les hicieron sobre el trabajo. Este mismo procedimiento se repitió con variables diferentes, pero no se obtuvieron resultados distintos a los presentados. Por tal motivo, se decide no realizar un modelo de predicción para la satisfacción del trabajo en los abuelos. En primera instancia se pensó que este comportamiento se debía a que la mayoría de los abuelos estaban pensionados, pero si se observan los abuelos pensionados:

```{r, echo=FALSE, fig.width=6, fig.height=4}
resum_1<- df_trabajo %>% count(RECIBIO_PENSIONES, sort=TRUE)
ggplot(resum_1, aes(x=reorder(RECIBIO_PENSIONES, n), y=n))+
  geom_col(fill="Black",alpha=0.4)+
  ggtitle("¿Recibe pensión?")+
  theme(plot.title = element_text(hjust = 0.5))+
  ylab("Cantidad de registros")+
  xlab("Respuesta")+
  geom_text(aes(label=n), position = "stack", hjust = 0.5,vjust=-0.1, size=2.5)
```

la gran mayoría de estos respondieron que no recibían algún tipo de pensión (2). Por tanto, se puede inferir que la mayoría de los abuelos no trabajan y tampoco reciben pensión, es decir, viven dependientes de sus familiares.

## Modelos Predictivos en Niños
```{r, echo = F}
# los datos:
ninos <- read.csv2("Datos/datos_ninos.csv", header=TRUE, dec=".", encoding="UTF-8")
```
### Correlaciones
```{r, echo = F}
corr_ninos <- ninos %>% select(SATISFACCION, ESTADO_SALUD, ACTIVIDADES, ETNIA, 
                               CONDIC_VIDA_HOGAR, INCRESOS_AUTOPERCIBIDOS_HOGAR,
                               PERCAPITA, CANT_PERSONAS_HOGAR, ESCUELA_OFICIAL,
                               VALOR_BECA, ORIGEN_SUBSIDIO_EDUC, UBICACION_ESCUELA, 
                               TRANSPORTE_ESCUELA, TIEMPO_TRANSPORTE_ESC, 
                               EDUCACION_PADRES ,ACTIVIDAD_ULT_SEMANA, 
                               LUGAR_TRABAJO, ENFERMEDAD_CRONICA, INCAP)

M = cor(corr_ninos, use = "pairwise.complete.obs")

M[is.na(M)]=0

ggcorrplot(M, hc.order = TRUE, type = "lower", lab = TRUE,tl.cex = 6, 
            pch.col = "red", lab_size = 2)

```

Los datos para niños:
```{r, echo = F}
df_ninos <- ninos %>% select(INCAP, SATISFACCION, 
                             PERCAPITA, INCRESOS_AUTOPERCIBIDOS_HOGAR, 
                             UBICACION_ESCUELA, EDUCACION_PADRES,
                             CONDIC_VIDA_HOGAR, TIEMPO_TRANSPORTE_ESC, HORAS_TRABAJO)

df_ninos['ETNIA'] = as.factor(ninos[,'ETNIA'])

df_ninos['VIVE_CON_PADRE'] = factor(ninos[,'VIVE_CON_PADRE'], labels = c(TRUE, 
                                                                         FALSE, 
                                                                         'Muerto'))

df_ninos['VIVE_CON_MADRE'] = factor(ninos[,'VIVE_CON_MADRE'], labels = c(TRUE, 
                                                                         FALSE, 
                                                                         'Muerto'))

df_ninos['ESCUELA_OFICIAL'] = factor(ninos[,'ESCUELA_OFICIAL'], labels = c('Oficial', 
                                                              'conSubstito', 
                                                              'SinSubstito'))

df_ninos['TRANSPORTE_ESCUELA'] = addNA(factor(ninos[,'TRANSPORTE_ESCUELA'], 
                                        labels = c('Carro', 'escolar', 'público',
                                                   'pie', 'Bicicleta', 'Caballo',
                                                   'canoa', 'Otro')))

df_ninos['ENFERMEDAD_CRONICA'] =  addNA(factor(ninos[,'ENFERMEDAD_CRONICA'], 
                                               labels = c(TRUE, FALSE)))

df_ninos['ACTIVIDAD_ULT_SEMANA'] = addNA(factor(ninos[,'ACTIVIDAD_ULT_SEMANA'], 
                                          labels = c( 'Trabajando', 'Buscando',
                                                      'Estudiando', 'Oficios_hogar', 
                                                      'Incapacitado trabajar', 'Otra')))

df_ninos['LUGAR_TRABAJO'] = addNA(factor(ninos[,'LUGAR_TRABAJO'], 
                                         labels = c('no trabajo', 'la vivienda',
                                                    'otra vivienda', 'Puerta', 
                                                    'calle', 'oficina', 'campo',
                                                    'obra')))

head(df_ninos)
```
### Resultados del entrenamiento

* Separación de los datos en entrenamiento y prueba
```{r, echo = F}
datos1 <- sample(2, nrow(df_ninos),
                   replace = TRUE,
                    prob = c(0.75, 0.25))

train <- df_ninos[datos1 == 1,]
test <- df_ninos[datos1 == 2,]
```

* Modelo de árbol de decisión
```{r, echo = F}
ctreeNiños <- ctree(formula = SATISFACCION ~ ., data=train, 
                controls = ctree_control(mincriterion = 0.7))

save(file="App/data/modeloSatisfaccionNiños.RData",
                              list=c("ctreeNiños"))
save(file="App/data/dfNinos.RData",
                              list=c("df_ninos"))
```

```{r, echo = F}
test_pred <- predict(ctreeNiños, newdata = test)
colnames(test_pred) <- c('pred_Satisfaccion')
test_pred <- cbind(test_pred, test['SATISFACCION'])

cat_test_pred = lapply(test_pred/5.6, as.integer)
table(cat_test_pred)
```

```{r, echo = F}
train_pred <- predict(ctreeNiños, newdata = train)
colnames(train_pred) <- c('pred_Satisfaccion')
train_pred <- cbind(train_pred, train['SATISFACCION'])

cat_train_pred = lapply(train_pred/5.6, as.integer)
table(cat_train_pred)
```
### Calificación por "Feature Selection"
En lo consiguiente calculamos unas métricas para mejorar el arbol:
Sacamos paso a paso una del los variables y miramos que impacto tiene cada.

#### Resultados:
* CANT_PERSONAS_HOGAR y EDAD tienen un impacto negativo en los datos de la prueba y positivo en entrenamiento. Esto significa que estos variables pruducen "overfitting".  
* PERCAPITA, INCRESOS_AUTOPERCIBIDOS_HOGAR, UBICACION_ESCUELA, EDUCACION_PADRES, CONDIC_VIDA_HOGAR, ETNIA, ESCUELA_OFICIAL, TRANSPORTE_ESCUELA, EDUCACION_PADRES, ACTIVIDAD_ULT_SEMANA, ENFERMEDAD_CRONICA tienen un impacto estrictamente positivo.  
* INCAP, LUGAR_TRABAJO, TIEMPO_TRANSPORTE_ESC tienen a veses un impacto positivo y en otros casos producen overfitting. Decidimos usar estos variables porque el impacto positivo es más grande que el negativo.  
* HORAS_TRABAJO y VALOR_BECA no van a usar, sin embargo, tienen una impacto positivo. Sacamos VALOR_BECA porque la correlación que hemos visto antes depende mucho de un valor atípico.  

#### Cálculo de métricas 
```{r, echo = F}
MSE_train <- mean((train_pred$SATISFACCION - train_pred$pred_Satisfaccion)^2)

MS_train <- mean(train_pred$SATISFACCION)^2

MSE_cat_train <- mean((cat_train_pred$SATISFACCION - cat_train_pred$pred_Satisfaccion)^2)

MS_cat_train <- mean(cat_train_pred$SATISFACCION)^2

MAE_train <- mean(abs(train_pred$SATISFACCION - train_pred$pred_Satisfaccion))

MAE_cat_train <- mean(abs(cat_train_pred$SATISFACCION - cat_train_pred$pred_Satisfaccion))

RMSE_cat_train <- sqrt(mean((cat_train_pred$SATISFACCION - cat_train_pred$pred_Satisfaccion)^2))
```

Entrenamiento
- MSE: `r MSE_train`  
- MS: `r MS_train`  
- MAE: `r MAE_train`  
Para las 10 categorías
- MSE: `r MSE_cat_train`  
- MS: `r MS_cat_train`  
- MAE: `r MAE_cat_train`  
- RMSE: `r RMSE_cat_train`  


```{r}
MSE_test <- mean((test_pred$SATISFACCION - test_pred$pred_Satisfaccion)^2)

MSE_cat_test <- mean((cat_test_pred$SATISFACCION - cat_test_pred$pred_Satisfaccion)^2)

MAE_test <- mean(abs(test_pred$SATISFACCION - test_pred$pred_Satisfaccion))

MAE_cat_test <- mean(abs(cat_test_pred$SATISFACCION - cat_test_pred$pred_Satisfaccion))

RMSE_test <- sqrt(mean((cat_test_pred$SATISFACCION - cat_test_pred$pred_Satisfaccion)^2))
```
Prueba
- MSE: `r MSE_test`  
- MAE: `r MAE_test`  
Para las 10 categorías
- MSE: `r MSE_cat_test`  
- MAE: `r MAE_cat_test`  
- RMSE: `r RMSE_test`  


#### Matriz de confusión de los datos
Entrenamiento
```{r}
# to factor
cat_train_pred$SATISFACCION = factor(cat_train_pred$SATISFACCION)
cat_train_pred$pred_Satisfaccion = factor(cat_train_pred$pred_Satisfaccion)

#reorder
cat_train_pred$pred_Satisfaccion = factor(cat_train_pred$pred_Satisfaccion, 
                                          levels=c(0,1,2,3,4,5,6,7,8,9))

#create confusion matrix
confusionMatrix(table(cat_train_pred))

```
Prueba
```{r}
# to factor
cat_test_pred$SATISFACCION = factor(cat_test_pred$SATISFACCION)
cat_test_pred$pred_Satisfaccion = factor(cat_test_pred$pred_Satisfaccion)

#reorder
cat_test_pred$SATISFACCION = factor(cat_test_pred$SATISFACCION, 
                                    levels=c(0,1,2,3,4,5,6,7,8,9))

cat_test_pred$pred_Satisfaccion = factor(cat_test_pred$pred_Satisfaccion, 
                                         levels=c(0,1,2,3,4,5,6,7,8,9))

#create confusion matrix
confusionMatrix(table(cat_test_pred))
levels(cat_test_pred$SATISFACCION)
```


# Conclusiones

* El modelo KNN no se ajustó a los datos categóricos, por tanto se tuvieron que ajustar con modelos de regresión lineal.  
* Las variables no se correlacionaron como se esperaba. Un motivo puede ser que las correlaciones utilizadas no hayan sido las adecuadas para este tipo de datos.  

# Recomendaciones

* Realizar un análisis más detallado sobre las variables categóricas ya que en este estudio se mezclaron con continuas, lo cual genera dudas en los resultados.  
* Realizar una ingenería de características con mayor detenimiento ya que muchas variables que por sí solas no aportan, pero al juntar otras pueden generar información valiosa.
* Probar con otros modelos que realizan una mejor precisión para datos categóricos.

# Bibliografía

[1]  Ramírez Pérez, Mauricio; Lee Maturana, Sau-Lyn (2012). Factores asociados a la satisfacción vital en adultos mayores de 60 años. Polis (Santiago), 11(33), 407–428. doi:10.4067/s0718-65682012000300020  
[2] Kutubaeva RZh (2019) Analysis of life satisfaction of the elderly population on the example of Sweden, Austria and Germany. Population and Economics 3(3): 102-116. https://doi.org/10.3897/popecon.3.e47192  
[3] Palmore, E., Luikart, C. (1972). Health and Social Factors Related to Life Satisfaction. Journal of Health and Social Behavior, 13(1), 68–80. doi: 10.2307/2136974  
[4] Naidu, Aditi (2009). Factors affecting patient satisfaction and healthcare quality. International Journal of Health Care Quality Assurance, 22(4), 366–381. doi:10.1108/09526860910964834  
[5] ROBLES-GARCIA, Monica et al. Variables relacionadas con la satisfaccion laboral: un estudio transversal a partir del modelo EFQM. Gac Sanit [online]. 2005, vol.19, n.2, pp.127-134. ISSN 0213-9111  
[6] Booth, Jaime; Ayers, Stephanie L.; and Marsiglia, Flavio F. (2012) "Perceived Neighborhood Safety and Psychological Distress: Exploring Protective Factors," The Journal of Sociology \& Social Welfare: Vol. 39 : Iss. 4 , Article 8. Available at: https://scholarworks.wmich.edu/jssw/vol39/iss4/  
[7] https://ourworldindata.org/happiness-and-life-satisfaction  


